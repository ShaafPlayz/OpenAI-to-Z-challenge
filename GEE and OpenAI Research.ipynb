{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1778a5c4-334d-4f08-ae23-6dbdc108d324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import os\n",
    "import dotenv\n",
    "import base64\n",
    "import textwrap\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import h5py\n",
    "import os\n",
    "import folium\n",
    "from IPython.display import display\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e32f4",
   "metadata": {},
   "source": [
    "# Code Relevant to Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "40df251a-0873-4401-8d00-47446c2c743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Google Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='iconic-guard-454717-v9')\n",
    "dataset = 'COPERNICUS/S2_SR_HARMONIZED'\n",
    "\n",
    "\n",
    "# Get Data from Google Earth Engine\n",
    "def getSatImageryGEE(c1, c2):\n",
    "    location = ee.Geometry.Point([c2 , c1])\n",
    "    region = location.buffer(7000) \n",
    "    image = ee.ImageCollection(dataset) \\\n",
    "                .filterBounds(region) \\\n",
    "                .filterDate('2023-06-01', '2024-06-30') \\\n",
    "                .sort('CLOUDY_PIXEL_PERCENTAGE') \\\n",
    "                .first() \\\n",
    "                .select(['B4', 'B3', 'B2'])  # RGB bands\n",
    "\n",
    "    return image, region\n",
    "\n",
    "# Download the Data parsed from GEE\n",
    "def downloadSatIGEE(c1, c2):\n",
    "    image, region = getSatImageryGEE(c1, c2)\n",
    "    geemap.ee_export_image(\n",
    "        image, filename='satimagery/sentinel_rgb.tif', scale=10, region=region\n",
    "        # Scale = 10m\n",
    "    )\n",
    "\n",
    "# Convert tif -> jpg\n",
    "def GEE_to_brightJPG():\n",
    "    img = Image.open(\"satimagery/sentinel_rgb.tif\")\n",
    "\n",
    "    # Convert to RGB and normalize brightness\n",
    "    img = img.convert(\"RGB\")\n",
    "\n",
    "    # Enhance brightness slightly (optional)\n",
    "    img = Image.eval(img, lambda x: x * 50)  # brighten by factor of 2\n",
    "\n",
    "    # Save as JPEG\n",
    "    img.save(\"satimagery/sentinel_rgb.jpg\", \"JPEG\")\n",
    "    print(\"Image Converted to JPG.\")\n",
    "\n",
    "# Encode the image because apparently gpt can't accept it otherwise\n",
    "def prepareJPG_forOpenAI():\n",
    "    with open(\"satimagery/sentinel_rgb.jpg\", \"rb\") as f:\n",
    "        base64_image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    # Format for OpenAI model\n",
    "    image_content = {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        }\n",
    "    }\n",
    "    return image_content\n",
    "\n",
    "# Download + Convert + PrepForOpenAI\n",
    "def getGEEImagery(c1, c2):\n",
    "    downloadSatIGEE(c1, c2)\n",
    "    GEE_to_brightJPG()\n",
    "    ex = prepareJPG_forOpenAI()\n",
    "    \n",
    "    print(\"Image Prepared for OpenAI export.\")\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e95c9",
   "metadata": {},
   "source": [
    "# Code Relevant to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4e45ac56-fd22-44d3-9dfc-463aeeaf1503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OpenAI\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "if not os.getenv(\"GITHUB_TOKEN\"):\n",
    "    raise ValueError(\"GITHUB_TOKEN is not set\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"GITHUB_TOKEN\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://models.github.ai/inference\"\n",
    "\n",
    "model = \"openai/o3-mini\" # or \"openai/gpt-4o\"\n",
    "client = OpenAI()\n",
    "\n",
    "# Sending Prompt + Image to OpenAI Model\n",
    "def promptModel(p, i):\n",
    "    modeloutput = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You're a geospatial analyst.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": p},\n",
    "                    i\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "        model=model\n",
    "    )\n",
    "    return modeloutput\n",
    "\n",
    "# Sending Prompt to OpenAI Model\n",
    "def promptONLY(p):\n",
    "    modeloutput = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You're a geospatial analyst.\"},\n",
    "            {\"role\": \"user\", \"content\": p}\n",
    "        ],\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "    )\n",
    "    return modeloutput\n",
    "\n",
    "\n",
    "# Printing Data\n",
    "def printoutput(r, d, option):\n",
    "    print(\"\\n\")\n",
    "    print(f\"OpenAI Model: {model}\")\n",
    "    print(f\"Dataset ID: {d} \\n\")\n",
    "    print(\"Model Response:\")\n",
    "    content = r.choices[0].message.content\n",
    "\n",
    "    if option == 1:\n",
    "        wrapped = textwrap.fill(content, width=100)\n",
    "        print(wrapped)\n",
    "    elif option == 2:\n",
    "        sections = content.split('*')\n",
    "        for section in sections:\n",
    "            print(section.strip())\n",
    "\n",
    "\n",
    "# Prompt OpenAI Model + Attach Image\n",
    "def promptGPT(c1, c2, p, option):\n",
    "    if option == 1:\n",
    "        imagePreped = getGEEImagery(c1, c2)\n",
    "        return promptModel(p, imagePreped)\n",
    "    elif option == 2:\n",
    "        return promptONLY(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377af68",
   "metadata": {},
   "source": [
    "# External DataSets I found\n",
    "appEEARS_AmazonRainforest = \"https://appeears.earthdatacloud.nasa.gov/download/1a6f2238-d420-498e-9bd7-6340ed3268ed\"\n",
    "\n",
    "DataSet ID = MCD12Q1.061\n",
    "\n",
    "DataSet Name = MODIS Land Cover Type Yearly L3 Global 500m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5345e034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1/projects/iconic-guard-454717-v9/thumbnails/bf7d6899f7ac61b8f93a115b04da9920-c48f3542741b58f2e3b398c50f3b87a8:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to c:\\Users\\shaaf\\OneDrive\\Desktop\\Shaaf Media\\Coding\\GitHub Files\\OpenAI-to-Z-challenge\\satimagery\\sentinel_rgb.tif\n",
      "Image Converted to JPG.\n",
      "Image Prepared for OpenAI export.\n"
     ]
    }
   ],
   "source": [
    "X = -3.314660\n",
    "Y = -61.355873\n",
    "\n",
    "A = getGEEImagery(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "22dbc41e-585c-40fc-87ba-809a8bf9df8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1/projects/iconic-guard-454717-v9/thumbnails/57bce28320c08ab0836bad8db6054f8d-613c54a29dc1958296ba781905fef894:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to c:\\Users\\shaaf\\OneDrive\\Desktop\\Shaaf Media\\Coding\\GitHub Files\\OpenAI-to-Z-challenge\\satimagery\\sentinel_rgb.tif\n",
      "Image Converted to JPG.\n",
      "Image Prepared for OpenAI export.\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Invalid content type. image_url is only supported by certain models.', 'type': 'invalid_request_error', 'param': 'messages.[1].content.[1].type', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[180], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m dataset_GEE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescribe surface features in plain English based on this satellite image.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m printoutput(promptGPT(X, Y, prompt, \u001b[38;5;241m1\u001b[39m), dataset, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[177], line 67\u001b[0m, in \u001b[0;36mpromptGPT\u001b[1;34m(c1, c2, p, option)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m option \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     66\u001b[0m     imagePreped \u001b[38;5;241m=\u001b[39m getGEEImagery(c1, c2)\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m promptModel(p, imagePreped)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m option \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m promptONLY(p)\n",
      "Cell \u001b[1;32mIn[177], line 15\u001b[0m, in \u001b[0;36mpromptModel\u001b[1;34m(p, i)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpromptModel\u001b[39m(p, i):\n\u001b[1;32m---> 15\u001b[0m     modeloutput \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     16\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     17\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre a geospatial analyst.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     18\u001b[0m             {\n\u001b[0;32m     19\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     21\u001b[0m                     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: p},\n\u001b[0;32m     22\u001b[0m                     i\n\u001b[0;32m     23\u001b[0m                 ]\n\u001b[0;32m     24\u001b[0m             }\n\u001b[0;32m     25\u001b[0m         ],\n\u001b[0;32m     26\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m     27\u001b[0m         top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m     28\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel\n\u001b[0;32m     29\u001b[0m     )\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m modeloutput\n",
      "File \u001b[1;32mc:\\Users\\shaaf\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shaaf\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    927\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    928\u001b[0m             {\n\u001b[0;32m    929\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    930\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    931\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m    932\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    933\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    934\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    935\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    936\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    937\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    938\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    939\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    940\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m    941\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    942\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    943\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m    944\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    945\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m    946\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    947\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    948\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    949\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    950\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    951\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    952\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    953\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    954\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    955\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    956\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    957\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    958\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    959\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m    960\u001b[0m             },\n\u001b[0;32m    961\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[0;32m    962\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m    963\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[0;32m    964\u001b[0m         ),\n\u001b[0;32m    965\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    966\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    967\u001b[0m         ),\n\u001b[0;32m    968\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    969\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    970\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    971\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\shaaf\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\shaaf\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1037\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1036\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1037\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Invalid content type. image_url is only supported by certain models.', 'type': 'invalid_request_error', 'param': 'messages.[1].content.[1].type', 'code': None}}"
     ]
    }
   ],
   "source": [
    "# Coordinates for Manaus, Brazil (Amazon Rainforest)\n",
    "\n",
    "## Only Works for GPT 4.1\n",
    "## GEE data are images and other OpenAI models do not support direct\n",
    "## image dump\n",
    "dataset_GEE = \"\"\n",
    "prompt = \"Describe surface features in plain English based on this satellite image.\"\n",
    "\n",
    "printoutput(promptGPT(X, Y, prompt, 1), dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5f60773e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({10: 3229248, 255: 1422346, 3: 69843, 20: 16631, 30: 11977, 9: 563, 40: 200, 1: 4})\n"
     ]
    }
   ],
   "source": [
    "# We now begin visualizing the second Dataset\n",
    "\n",
    "from collections import Counter\n",
    "import rasterio\n",
    "\n",
    "with rasterio.open(\"AppEEARS/MCD12Q1.061_LC_Prop2_doy2020001_aid0001.tif\") as src:\n",
    "    data = src.read(1)\n",
    "\n",
    "counts = Counter(data.flatten())\n",
    "print(counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "90b20e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Data (Class 255): 1422346 pixels\n",
      "Urban Areas (Class 10): 3229248 pixels\n",
      "Deciduous Needleleaf Trees (Class 3): 69843 pixels\n",
      "Unknown (Class 30): 11977 pixels\n",
      "Unknown (Class 20): 16631 pixels\n",
      "Unknown (Class 40): 200 pixels\n",
      "Flooded Vegetation (Class 9): 563 pixels\n",
      "Evergreen Needleleaf Trees (Class 1): 4 pixels\n"
     ]
    }
   ],
   "source": [
    "# Readable Text\n",
    "modis_pft_classes = {\n",
    "    1: \"Evergreen Needleleaf Trees\",\n",
    "    3: \"Deciduous Needleleaf Trees\",\n",
    "    9: \"Flooded Vegetation\",\n",
    "    10: \"Urban Areas\",\n",
    "    20: \"Unknown\",\n",
    "    30: \"Unknown\",\n",
    "    40: \"Unknown\",\n",
    "    255: \"No Data\"\n",
    "}\n",
    "\n",
    "summary = []\n",
    "for code, count in counts.items():\n",
    "    label = modis_pft_classes.get(code, \"Unknown\")\n",
    "    summary.append(f\"{label} (Class {code}): {count} pixels\")\n",
    "\n",
    "report_text = \"\\n\".join(summary)\n",
    "print(report_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "03bde518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "OpenAI Model: openai/o3-mini\n",
      "Dataset ID: MCD12Q1.061 \n",
      "\n",
      "Model Response:\n",
      "\n",
      "\n",
      "\n",
      "### Summary Table\n",
      "\n",
      "\n",
      "| Land Cover Type                 | Class Code | Pixel Count |\n",
      "|---------------------------------|------------|-------------|\n",
      "| No Data                         | 255        | 1,422,346   |\n",
      "| Urban Areas                     | 10         | 3,229,248   |\n",
      "| Deciduous Needleleaf Trees      | 3          | 69,843      |\n",
      "| Unknown                         | 30         | 11,977      |\n",
      "| Unknown                         | 20         | 16,631      |\n",
      "| Unknown                         | 40         | 200         |\n",
      "| Flooded Vegetation              | 9          | 563         |\n",
      "| Evergreen Needleleaf Trees      | 1          | 4           |\n",
      "\n",
      "\n",
      "### Key Insights\n",
      "\n",
      "\n",
      "- Urban Areas have the highest pixel count, dominating the dataset.\n",
      "- A sizable number of pixels are marked as No Data.\n",
      "- Deciduous needleleaf trees and flooded vegetation are minimally represented.\n",
      "- The Unknown classes vary in pixel counts, suggesting classification uncertainties.\n",
      "\n",
      "\n",
      "### Interpretation\n",
      "\n",
      "\n",
      "Urban areas and no data pixels dominate this dataset, implying\n",
      "\n",
      "significant urban sprawl and potential classification issues. Meanwhile, low counts\n",
      "\n",
      "in forest and flooded classes clearly indicate extremely limited vegetation cover.\n"
     ]
    }
   ],
   "source": [
    "prompt2 = f\"\"\"You are a geospatial analyst. Given the following MODIS land cover pixel counts (PFT classes), create a **concise, well-formatted markdown report** with:\n",
    "\n",
    "- A clean summary table with headers\n",
    "- Bullet-pointed key insights\n",
    "- A short paragraph interpretation (add a * after every 10 words)\n",
    "- Add in a * everytime a new line starts\n",
    "\n",
    "\n",
    "Here is the Data: \n",
    "{report_text}\n",
    "\"\"\"\n",
    "DataSet_ID = \"MCD12Q1.061\"\n",
    "printoutput(promptGPT(0, 0, prompt2, 2), DataSet_ID, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d71da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b16e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
